{
    "configs": [
        {
            "accumulate_grad_batches": 4,
            "base_type": "t5-3b",
            "batch_size": 4,
            "epochs": 30,
            "load_worker_num": 16,
            "load_prefetch_per_worker": 8,
            "l2_regularization": 0,
            "learning_rate": 1e-4,
            "load": false,
            "max_seq_length": 150,
            "qa_checkpoint_path": "/home/muhan/data/workspace/kb_encoder/train_ob_qa_deberta_v3_match/0/checkpoint/epoch=16-test_accuracy-test_accuracy=0.900.ckpt",
            "optimizer_class": "Adafactor",
            "use_matcher": true,
            "matcher_mode": "embedding",
            "matcher_config": {
                "question_match_max_times": 1000,
                "question_match_max_depth": 3,
                "question_match_edge_top_k": 10,
                "question_match_source_context_range": 1,
                "question_select_max_edges": 3,
                "question_select_discard_edges_if_rank_below": "auto",
                "choices_match_max_times": 1000,
                "choices_match_max_depth": 1,
                "choices_match_edge_top_k": 10,
                "choices_match_source_context_range": 1,
                "choices_select_max_edges": 2,
                "choices_select_discard_edges_if_rank_below": "auto"
            },
            "seed": 697474,
            "save": true
        }
    ],
    "early_stopping_patience": 15,
    "gpus": [0],
    "stages": ["openbook_qa_with_search"],
    "working_directory": "/home/muhan/data/workspace/kb_encoder/train_ob_qa_deberta_v3_with_search"
}
